# =============================================================================
# ELAOMS Production Environment Configuration
# =============================================================================
# This file contains all environment variables for production deployment.
# Copy this file to .env and replace placeholder values with actual credentials.
#
# SECURITY NOTICE:
# - NEVER commit .env to version control
# - Use strong, unique secrets for all keys
# - Restrict file permissions: chmod 600 .env
# - Consider using a secrets manager for sensitive values
# =============================================================================

# =============================================================================
# ELEVENLABS CONFIGURATION
# =============================================================================
# Primary API key for ElevenLabs SDK
# Get this from: https://elevenlabs.io/app/settings/api-keys
ELEVENLABS_API_KEY=sk-el-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# HMAC secret for post-call webhook validation (REQUIRED)
# Get this from your ElevenLabs Agent webhook configuration
# Must be a strong, random secret (min 32 characters recommended)
ELEVENLABS_POST_CALL_KEY=your-strong-post-call-hmac-secret-min-32-chars

# API key for client-data webhook authentication
# Used for X-Api-Key header validation on /webhooks/client-data endpoint
ELEVENLABS_CLIENT_DATA_KEY=your-strong-client-data-api-key-min-32-chars

# HMAC secret for search-data webhook validation (reserved for future use)
ELEVENLABS_SEARCH_DATA_KEY=your-strong-search-data-hmac-secret-min-32-chars

# =============================================================================
# OPENMEMORY CONNECTION
# =============================================================================
# API key for OpenMemory authentication
# Must match OM_API_KEY on the OpenMemory server
OPENMEMORY_KEY=your-openmemory-api-key-here

# OpenMemory service URL (full URL for remote, or port for local)
# For production, use full URL with HTTPS if behind reverse proxy
OPENMEMORY_PORT=http://127.0.0.1:8080

# Path reference for OpenMemory database (informational)
OPENMEMORY_DB_PATH=/var/lib/openmemory/openmemory.db

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# Directory for saving conversation payloads (transcripts, audio references)
# Ensure proper permissions and adequate disk space
# Production recommendation: Use dedicated storage volume
PAYLOAD_STORAGE_PATH=/var/lib/elaoms/payloads

# =============================================================================
# =============================================================================
# OPENMEMORY SERVER CONFIGURATION
# =============================================================================
# The following variables configure the OpenMemory server itself.
# These should be set in the OpenMemory service's environment.
# =============================================================================

# =============================================================================
# OPENMEMORY BACKEND SERVER
# =============================================================================
# Server port (default: 8080)
OM_PORT=8080

# API authentication key - MUST match OPENMEMORY_KEY above
# Use a strong, random key (min 32 characters)
OM_API_KEY=your-openmemory-api-key-here

# Enable rate limiting (highly recommended for production)
OM_RATE_LIMIT_ENABLED=true

# Rate limit window in milliseconds (60000 = 1 minute)
OM_RATE_LIMIT_WINDOW_MS=60000

# Maximum requests per rate limit window
OM_RATE_LIMIT_MAX_REQUESTS=200

# Log authenticated requests (useful for debugging, disable in high-traffic production)
OM_LOG_AUTH=false

# Anonymous telemetry (set to false for privacy)
OM_TELEMETRY=false

# Server mode: standard, cluster, or readonly
OM_MODE=standard

# =============================================================================
# OPENMEMORY METADATA STORE (PostgreSQL for Production)
# =============================================================================
# Backend type: sqlite (dev) or postgres (production)
OM_METADATA_BACKEND=postgres

# SQLite path (only used if OM_METADATA_BACKEND=sqlite)
OM_DB_PATH=/var/lib/openmemory/openmemory.sqlite

# PostgreSQL Configuration (recommended for production)
OM_PG_HOST=localhost
OM_PG_PORT=5432
OM_PG_DB=openmemory
OM_PG_USER=openmemory
OM_PG_PASSWORD=your-strong-postgres-password-here
OM_PG_SCHEMA=public
OM_PG_TABLE=openmemory_memories

# PostgreSQL SSL Mode: disable, require, verify-ca, verify-full
# For production, use 'require' minimum, 'verify-full' for highest security
OM_PG_SSL=require

# =============================================================================
# OPENMEMORY VECTOR STORE
# =============================================================================
# Vector storage backend: sqlite, postgres, or weaviate
# For production with high volume, consider weaviate for better performance
OM_VECTOR_BACKEND=postgres

# Vector table name (for postgres backend)
OM_VECTOR_TABLE=vectors

# Weaviate Configuration (alternative vector store for large scale)
# OM_VECTOR_BACKEND=weaviate
# OM_WEAVIATE_URL=https://your-weaviate-instance.weaviate.network
# OM_WEAVIATE_API_KEY=your-weaviate-api-key
# OM_WEAVIATE_CLASS=OpenMemory

# =============================================================================
# OPENMEMORY EMBEDDINGS
# =============================================================================
# Embedding provider: openai, gemini, bedrock, ollama, local, synthetic
# For production, openai or bedrock recommended for quality
OM_EMBEDDINGS=openai

# Fallback providers (comma-separated, used if primary fails)
OM_EMBEDDING_FALLBACK=synthetic

# Embedding mode: simple (single), batch, or parallel
OM_EMBED_MODE=batch

# Advanced parallel embedding (for high throughput)
OM_ADV_EMBED_PARALLEL=true

# Delay between embedding requests (ms) - helps with rate limits
OM_EMBED_DELAY_MS=100

# OpenAI-compatible API base URL
OM_OPENAI_BASE_URL=https://api.openai.com/v1

# Maximum request payload size (bytes)
OM_MAX_PAYLOAD_SIZE=2000000

# =============================================================================
# API KEYS FOR EMBEDDING PROVIDERS
# =============================================================================
# OpenAI API Key (required if OM_EMBEDDINGS=openai)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google Gemini API Key (if using gemini embeddings)
# GEMINI_API_KEY=your-gemini-api-key

# AWS Credentials (if using bedrock embeddings)
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key
# AWS_REGION=us-east-1

# Ollama URL (if using local ollama)
# OLLAMA_URL=http://localhost:11434

# =============================================================================
# OPENMEMORY PERFORMANCE TIER
# =============================================================================
# Performance tier: hybrid (balanced), fast (speed), smart (quality), deep (comprehensive)
# hybrid recommended for most production workloads
OM_TIER=hybrid

# Keyword match boost multiplier for relevance scoring
OM_KEYWORD_BOOST=2.5

# Minimum keyword length for matching
OM_KEYWORD_MIN_LENGTH=3

# Minimum relevance score threshold (0.0 - 1.0)
OM_MIN_SCORE=0.3

# =============================================================================
# OPENMEMORY MEMORY DECAY SYSTEM
# =============================================================================
# Decay cycle frequency in minutes (how often to process memory decay)
OM_DECAY_INTERVAL_MINUTES=120

# Parallel decay workers
OM_DECAY_THREADS=4

# Threshold for moving memories to cold tier (0.0 - 1.0)
OM_DECAY_COLD_THRESHOLD=0.25

# Reinforce memory relevance when accessed
OM_DECAY_REINFORCE_ON_QUERY=true

# Enable regeneration of cold memories
OM_REGENERATION_ENABLED=true

# =============================================================================
# OPENMEMORY VECTOR CONFIGURATION
# =============================================================================
# Maximum vector dimensions (OpenAI ada-002 uses 1536)
OM_MAX_VECTOR_DIM=1536

# Minimum vector dimensions
OM_MIN_VECTOR_DIM=64

# Summary compression layers
OM_SUMMARY_LAYERS=3

# Use summary-only storage (reduces storage, maintains semantic quality)
OM_USE_SUMMARY_ONLY=true

# Maximum summary length in characters
OM_SUMMARY_MAX_LENGTH=300

# Memories per segment for batch processing
OM_SEG_SIZE=10000

# =============================================================================
# OPENMEMORY AUTO-REFLECTION & COMPRESSION
# =============================================================================
# Enable automatic reflection system
OM_AUTO_REFLECT=true

# Reflection cycle interval in minutes
OM_REFLECT_INTERVAL=30

# Minimum memories before triggering reflection
OM_REFLECT_MIN_MEMORIES=50

# Enable automatic compression
OM_COMPRESSION_ENABLED=true

# Minimum content length to trigger compression
OM_COMPRESSION_MIN_LENGTH=100

# Compression algorithm: auto, lz4, zstd, gzip
OM_COMPRESSION_ALGORITHM=auto

# =============================================================================
# OPENMEMORY LANGGRAPH INTEGRATION
# =============================================================================
# LangGraph namespace for memory isolation
OM_LG_NAMESPACE=elaoms

# Maximum context length for LangGraph queries
OM_LG_MAX_CONTEXT=100

# Enable reflective mode for deeper context understanding
OM_LG_REFLECTIVE=true
